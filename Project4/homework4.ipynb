{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avilez-dev-11/Projects-in-ML-AI/blob/main/homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq4oTpqgRr2H"
      },
      "source": [
        "# **Task 2 (75 points):**\n",
        "In this task, you will pick a dataset (time-series or any other form of\n",
        "sequential data) and an associated problem that can be solved via sequence models. You must\n",
        "describe why you need sequence models to solve this problem. Include a link to the dataset\n",
        "source. Next, you should pick an RNN framework that you would use to solve this problem (This\n",
        "framework can be in TensorFlow, PyTorch or any other Python Package)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:09.749777Z",
          "iopub.status.busy": "2024-02-27T17:06:09.749125Z",
          "iopub.status.idle": "2024-02-27T17:06:10.496169Z",
          "shell.execute_reply": "2024-02-27T17:06:10.4953Z",
          "shell.execute_reply.started": "2024-02-27T17:06:09.749742Z"
        },
        "id": "Tjo-Zx9oRr2K",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Projects_ML_AI/Project4/file.csv\")\n",
        "SEED = 5555"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.497929Z",
          "iopub.status.busy": "2024-02-27T17:06:10.497632Z",
          "iopub.status.idle": "2024-02-27T17:06:10.508063Z",
          "shell.execute_reply": "2024-02-27T17:06:10.507132Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.497903Z"
        },
        "id": "ReM8v3iGRr2L",
        "outputId": "ab0c4465-6d96-4a21-e357-e8b41d269c6d",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                             tweets   labels\n",
              "0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "1           1  Try talking with ChatGPT, our new AI system wh...     good\n",
              "2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "3           3  THRILLED to share that ChatGPT, our new model ...     good\n",
              "4           4  As of 2 minutes ago, @OpenAI released their ne...      bad"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.509591Z",
          "iopub.status.busy": "2024-02-27T17:06:10.509278Z",
          "iopub.status.idle": "2024-02-27T17:06:10.584037Z",
          "shell.execute_reply": "2024-02-27T17:06:10.582644Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.509565Z"
        },
        "id": "yjMt9l-GRr2L",
        "outputId": "90052d06-ba4d-4fc7-c7b3-ed5c0ddf7455",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Unnamed: 0    0\n",
              "tweets        0\n",
              "labels        0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0jG8hAVRr2L"
      },
      "source": [
        "The absence of null values in the dataset ensures data integrity and reduces the need for data preprocessing steps like imputation. This can potentially improve the training efficiency and effectiveness of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.587324Z",
          "iopub.status.busy": "2024-02-27T17:06:10.58693Z",
          "iopub.status.idle": "2024-02-27T17:06:10.606817Z",
          "shell.execute_reply": "2024-02-27T17:06:10.605792Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.587281Z"
        },
        "id": "qnhqz0oZRr2M",
        "outputId": "bc825500-4490-4747-b60f-c09a086bf557",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219289</th>\n",
              "      <td>Other Software Projects Are Now Trying to Repl...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219290</th>\n",
              "      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n",
              "      <td>good</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219291</th>\n",
              "      <td>chatgpt is being disassembled until it can onl...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219292</th>\n",
              "      <td>2023 predictions by #chatGPT. Nothing really s...</td>\n",
              "      <td>bad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219293</th>\n",
              "      <td>From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>219294 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweets   labels\n",
              "0       ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "1       Try talking with ChatGPT, our new AI system wh...     good\n",
              "2       ChatGPT: Optimizing Language Models for Dialog...  neutral\n",
              "3       THRILLED to share that ChatGPT, our new model ...     good\n",
              "4       As of 2 minutes ago, @OpenAI released their ne...      bad\n",
              "...                                                   ...      ...\n",
              "219289  Other Software Projects Are Now Trying to Repl...      bad\n",
              "219290  I asked #ChatGPT to write a #NYE Joke for SEOs...     good\n",
              "219291  chatgpt is being disassembled until it can onl...      bad\n",
              "219292  2023 predictions by #chatGPT. Nothing really s...      bad\n",
              "219293   From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0  neutral\n",
              "\n",
              "[219294 rows x 2 columns]"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df.drop(columns = [\"Unnamed: 0\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQo_NQ-RRr2M"
      },
      "source": [
        "The first column labeled \"unnamed: 0\" was removed from the dataset. This column did not contain meaningful information relevant to the sentiment analysis task and was therefore considered an artifact of the data import process. Removing it helps improve the clarity and efficiency of subsequent data processing and model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.60843Z",
          "iopub.status.busy": "2024-02-27T17:06:10.60806Z",
          "iopub.status.idle": "2024-02-27T17:06:10.667931Z",
          "shell.execute_reply": "2024-02-27T17:06:10.667Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.608399Z"
        },
        "id": "0fUJxOyJRr2M",
        "outputId": "113be010-113b-47f7-ae6c-d1ba99d673c0",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "107796"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df[df[\"labels\"]== \"bad\"]) # negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.669712Z",
          "iopub.status.busy": "2024-02-27T17:06:10.669291Z",
          "iopub.status.idle": "2024-02-27T17:06:10.715766Z",
          "shell.execute_reply": "2024-02-27T17:06:10.714857Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.669671Z"
        },
        "id": "GzUqhj39Rr2M",
        "outputId": "247b1848-c49a-4eff-eddf-aa29d8bbe031",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "55487"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df[df[\"labels\"]== \"neutral\"]) # neutral"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.717257Z",
          "iopub.status.busy": "2024-02-27T17:06:10.716943Z",
          "iopub.status.idle": "2024-02-27T17:06:10.764463Z",
          "shell.execute_reply": "2024-02-27T17:06:10.763463Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.717226Z"
        },
        "id": "vEUm4krwRr2M",
        "outputId": "55344564-ab8a-4419-8dce-4185781b578c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "56011"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df[df[\"labels\"]== \"good\"]) # positive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61m0dBpKRr2N"
      },
      "source": [
        "Analysis of the data revealed a class imbalance, with significantly more negative comments (107796) than positive comments (56011). To address this and ensure a more balanced representation during model training, a downsampling technique was used. This involved randomly removing a specific number of observations from the majority class (negative comments) to match the size of the minority class (positive comments)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.766227Z",
          "iopub.status.busy": "2024-02-27T17:06:10.765795Z",
          "iopub.status.idle": "2024-02-27T17:06:10.912391Z",
          "shell.execute_reply": "2024-02-27T17:06:10.91143Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.766191Z"
        },
        "id": "RagJ5mjERr2N",
        "outputId": "ce893558-c0a4-47c7-be76-69bf687f5e8b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment distribution after undersampling:\n",
            "good       56011\n",
            "bad        55487\n",
            "neutral    55487\n",
            "Name: labels, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Load the dataset (assuming you have it in a DataFrame called 'df')\n",
        "\n",
        "# Identify indices of negative comments\n",
        "negative_indices = df[df['labels'] == 'bad'].index\n",
        "neutral_indices = len(df[df['labels'] == 'neutral'])\n",
        "\n",
        "# Calculate the number of negative comments to remove based on desired ratio or fixed number\n",
        "num_negative_to_remove = len(negative_indices) - neutral_indices  # For 1:1 ratio\n",
        "\n",
        "# Create a DataFrame of just those indices\n",
        "negatives_to_remove = negative_indices.to_frame(name='index')\n",
        "\n",
        "# Undersample the positives to remove (if any)\n",
        "if num_negative_to_remove > 0:\n",
        "    df_downsampled = resample(negatives_to_remove,\n",
        "                              replace=False,  # Don't sample with replacement\n",
        "                              n_samples=num_negative_to_remove,\n",
        "                              random_state=42)  # For reproducibility\n",
        "\n",
        "    # Drop those indices from the original DataFrame\n",
        "    df = df.drop(df_downsampled['index'])\n",
        "\n",
        "# Check the new distribution\n",
        "print(\"Sentiment distribution after undersampling:\")\n",
        "print(df['labels'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.914017Z",
          "iopub.status.busy": "2024-02-27T17:06:10.913658Z",
          "iopub.status.idle": "2024-02-27T17:06:10.956704Z",
          "shell.execute_reply": "2024-02-27T17:06:10.955898Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.913984Z"
        },
        "id": "TdE74L3URr2N",
        "outputId": "e6dd5fed-c817-47fd-c262-8a550bcb0d13",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "111498"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = df[df[\"labels\"] != \"neutral\"]# remove neutral\n",
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:10.996899Z",
          "iopub.status.busy": "2024-02-27T17:06:10.99648Z",
          "iopub.status.idle": "2024-02-27T17:06:11.092326Z",
          "shell.execute_reply": "2024-02-27T17:06:11.091378Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.996865Z"
        },
        "id": "03wFKQFSRr2N",
        "outputId": "63e6cbc9-7fc7-401e-c196-e3c9bc78cf4a",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df[\"labels\"] = df[\"labels\"].replace(\"bad\", 0)\n",
        "df[\"labels\"] = df[\"labels\"].replace(\"good\", 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkI4Dy05Rr2N"
      },
      "source": [
        "This dataset initially included ChatGPT tweets categorized under the sentiments: bad, neutral, and good. To focus on identifying distinctly negative or positive sentiments, neutral observations were removed. This decision was made because neutral tweets might not contribute strongly to model training when the goal is to distinguish between clear emotional states. Despite this filtering, we retain a substantial dataset that provides ample data for robust model training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJOQwsVmRr2O"
      },
      "source": [
        "**Part 1 (30 points):** Implement your RNN either using an existing framework OR you can\n",
        "implement your own RNN cell structure. In either case, describe the structure of your\n",
        "RNN and the activation functions you are using for each time step and in the output\n",
        "layer. Define a metric you will use to measure the performance of your model (NOTE:\n",
        "Performance should be measured both for the validation set and the test set)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:11.093886Z",
          "iopub.status.busy": "2024-02-27T17:06:11.09358Z",
          "iopub.status.idle": "2024-02-27T17:06:11.105467Z",
          "shell.execute_reply": "2024-02-27T17:06:11.104327Z",
          "shell.execute_reply.started": "2024-02-27T17:06:11.093859Z"
        },
        "id": "HK6tq5uYRr2O",
        "outputId": "5c79f228-4a25-4fce-c347-02acb95c6cf3",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Just launched ChatGPT, our new AI system which...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ChatGPT coming out strong refusing to help me ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219285</th>\n",
              "      <td>Podcast returns in 2023! üêàüåô\\n.\\n#ai #chatgpt #...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219286</th>\n",
              "      <td>There's now an open source alternative to Chat...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219287</th>\n",
              "      <td>One of my new favorite thing to do with #ChatG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219290</th>\n",
              "      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219291</th>\n",
              "      <td>chatgpt is being disassembled until it can onl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111498 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweets  labels\n",
              "1       Try talking with ChatGPT, our new AI system wh...       1\n",
              "3       THRILLED to share that ChatGPT, our new model ...       1\n",
              "4       As of 2 minutes ago, @OpenAI released their ne...       0\n",
              "5       Just launched ChatGPT, our new AI system which...       1\n",
              "7       ChatGPT coming out strong refusing to help me ...       1\n",
              "...                                                   ...     ...\n",
              "219285  Podcast returns in 2023! üêàüåô\\n.\\n#ai #chatgpt #...       0\n",
              "219286  There's now an open source alternative to Chat...       1\n",
              "219287  One of my new favorite thing to do with #ChatG...       1\n",
              "219290  I asked #ChatGPT to write a #NYE Joke for SEOs...       1\n",
              "219291  chatgpt is being disassembled until it can onl...       0\n",
              "\n",
              "[111498 rows x 2 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:11.107085Z",
          "iopub.status.busy": "2024-02-27T17:06:11.106789Z",
          "iopub.status.idle": "2024-02-27T17:06:12.191847Z",
          "shell.execute_reply": "2024-02-27T17:06:12.190928Z",
          "shell.execute_reply.started": "2024-02-27T17:06:11.10706Z"
        },
        "id": "qP9IF6T0Rr2O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_comment(comment: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans text, removing special characters, hashtags, and mentions while\n",
        "    preserving spaces and essential punctuation.\n",
        "\n",
        "    Args:\n",
        "        comment: The text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        The cleaned text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Regular expression to match and remove special characters\n",
        "    pattern = r\"[^a-zA-Z0-9\\s\\.!?,\\(\\)]+\"\n",
        "\n",
        "    # Clean the text using regular expressions\n",
        "    cleaned_text = re.sub(pattern, \"\", comment)\n",
        "\n",
        "    # Remove leading and trailing whitespace\n",
        "    cleaned_text = cleaned_text.strip()\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the cleaning function to the \"Comment\" column\n",
        "df[\"tweets\"] = df[\"tweets\"].apply(clean_comment)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:57:12.286372Z",
          "iopub.status.busy": "2024-02-27T18:57:12.285972Z",
          "iopub.status.idle": "2024-02-27T18:57:12.298312Z",
          "shell.execute_reply": "2024-02-27T18:57:12.297392Z",
          "shell.execute_reply.started": "2024-02-27T18:57:12.28634Z"
        },
        "id": "meWSFmaHRr2O",
        "outputId": "4a166b6e-55ed-4e01-e93c-807fd083ca9c",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Try talking with ChatGPT, our new AI system wh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>THRILLED to share that ChatGPT, our new model ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>As of 2 minutes ago, OpenAI released their new...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Just launched ChatGPT, our new AI system which...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ChatGPT coming out strong refusing to help me ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219285</th>\n",
              "      <td>Podcast returns in 2023! n.nai chatgpt artific...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219286</th>\n",
              "      <td>Theres now an open source alternative to ChatG...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219287</th>\n",
              "      <td>One of my new favorite thing to do with ChatGP...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219290</th>\n",
              "      <td>I asked ChatGPT to write a NYE Joke for SEOs a...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219291</th>\n",
              "      <td>chatgpt is being disassembled until it can onl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>111498 rows √ó 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   tweets  labels\n",
              "1       Try talking with ChatGPT, our new AI system wh...       1\n",
              "3       THRILLED to share that ChatGPT, our new model ...       1\n",
              "4       As of 2 minutes ago, OpenAI released their new...       0\n",
              "5       Just launched ChatGPT, our new AI system which...       1\n",
              "7       ChatGPT coming out strong refusing to help me ...       1\n",
              "...                                                   ...     ...\n",
              "219285  Podcast returns in 2023! n.nai chatgpt artific...       0\n",
              "219286  Theres now an open source alternative to ChatG...       1\n",
              "219287  One of my new favorite thing to do with ChatGP...       1\n",
              "219290  I asked ChatGPT to write a NYE Joke for SEOs a...       1\n",
              "219291  chatgpt is being disassembled until it can onl...       0\n",
              "\n",
              "[111498 rows x 2 columns]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:12.193324Z",
          "iopub.status.busy": "2024-02-27T17:06:12.193023Z",
          "iopub.status.idle": "2024-02-27T17:06:12.197931Z",
          "shell.execute_reply": "2024-02-27T17:06:12.196804Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.193299Z"
        },
        "id": "jcYVMBusRr2O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:12.199366Z",
          "iopub.status.busy": "2024-02-27T17:06:12.199059Z",
          "iopub.status.idle": "2024-02-27T17:06:12.295146Z",
          "shell.execute_reply": "2024-02-27T17:06:12.294335Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.199342Z"
        },
        "id": "fXkhf-R1Rr2O",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def convert_to_tfds(dataframe):\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dataframe['tweets'], dataframe['labels']))\n",
        "  dataset = dataset.shuffle(buffer_size=len(dataframe), seed=0)\n",
        "  return dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "training_set = df.copy()\n",
        "\n",
        "train, dev = train_test_split(training_set, test_size=0.1, random_state = 0)\n",
        "train, test = train_test_split(train, test_size = 0.1, random_state = 0)\n",
        "\n",
        "train_ds = convert_to_tfds(train)\n",
        "valid_ds = convert_to_tfds(dev)\n",
        "test_ds = convert_to_tfds(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:12.296795Z",
          "iopub.status.busy": "2024-02-27T17:06:12.296478Z",
          "iopub.status.idle": "2024-02-27T17:06:15.794176Z",
          "shell.execute_reply": "2024-02-27T17:06:15.79331Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.296768Z"
        },
        "id": "wsEZb9fZRr2P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "encoder = tf.keras.layers.TextVectorization()\n",
        "encoder.adapt(train_ds.map(lambda text, label: text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:15.795822Z",
          "iopub.status.busy": "2024-02-27T17:06:15.795443Z",
          "iopub.status.idle": "2024-02-27T17:06:16.498609Z",
          "shell.execute_reply": "2024-02-27T17:06:16.497644Z",
          "shell.execute_reply.started": "2024-02-27T17:06:15.795795Z"
        },
        "id": "_tVp4Q3ORr2P",
        "outputId": "09129951-78fd-4a9c-98b0-e7f9a4cd55e7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "160530"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(encoder.get_vocabulary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:16.500125Z",
          "iopub.status.busy": "2024-02-27T17:06:16.499814Z",
          "iopub.status.idle": "2024-02-27T17:06:17.43402Z",
          "shell.execute_reply": "2024-02-27T17:06:17.433156Z",
          "shell.execute_reply.started": "2024-02-27T17:06:16.50008Z"
        },
        "id": "1dWfZQt9Rr2P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:17.43578Z",
          "iopub.status.busy": "2024-02-27T17:06:17.43539Z",
          "iopub.status.idle": "2024-02-27T17:06:17.450482Z",
          "shell.execute_reply": "2024-02-27T17:06:17.4495Z",
          "shell.execute_reply.started": "2024-02-27T17:06:17.435739Z"
        },
        "id": "iOeKU2QMRr2P",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:06:17.451985Z",
          "iopub.status.busy": "2024-02-27T17:06:17.451655Z",
          "iopub.status.idle": "2024-02-27T17:23:00.581789Z",
          "shell.execute_reply": "2024-02-27T17:23:00.580776Z",
          "shell.execute_reply.started": "2024-02-27T17:06:17.451958Z"
        },
        "id": "CeV15O12Rr2P",
        "outputId": "263f5334-a2e7-4be0-db7d-5669f62b0ffa",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1412/1412 [==============================] - 224s 158ms/step - loss: 0.4031 - accuracy: 0.7861 - val_loss: 0.1653 - val_accuracy: 0.9396\n",
            "Epoch 2/5\n",
            "1412/1412 [==============================] - 224s 158ms/step - loss: 0.1174 - accuracy: 0.9607 - val_loss: 0.1270 - val_accuracy: 0.9578\n",
            "Epoch 3/5\n",
            "1412/1412 [==============================] - 220s 156ms/step - loss: 0.0543 - accuracy: 0.9834 - val_loss: 0.1337 - val_accuracy: 0.9526\n",
            "Epoch 4/5\n",
            "1412/1412 [==============================] - 222s 157ms/step - loss: 0.0290 - accuracy: 0.9918 - val_loss: 0.1507 - val_accuracy: 0.9583\n",
            "Epoch 5/5\n",
            "1412/1412 [==============================] - 228s 161ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.1618 - val_accuracy: 0.9474\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:23:00.583823Z",
          "iopub.status.busy": "2024-02-27T17:23:00.58319Z",
          "iopub.status.idle": "2024-02-27T17:23:02.913742Z",
          "shell.execute_reply": "2024-02-27T17:23:02.912742Z",
          "shell.execute_reply.started": "2024-02-27T17:23:00.583787Z"
        },
        "id": "OJeIG1E-Rr2P",
        "outputId": "22414a21-6176-4693-9d29-c8722750b5c3",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 6s 37ms/step - loss: 0.1673 - accuracy: 0.9470\n",
            "Loss: 0.16730956733226776\n",
            "Accuracy: 0.9469855427742004\n"
          ]
        }
      ],
      "source": [
        "# Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbq9jpP3Rr2P"
      },
      "source": [
        "This model utilizes a bidirectional recurrent neural network (BRNN) with an embedding layer for processing tokenized input data. Training the model required significant computation time, but the training accuracy increased steadily with additional epochs. While the final training accuracy reached a high of 94% with a relatively low loss of 18%, a potential case of underfitting is suggested by the discrepancy between the training (94%) and validation/test accuracies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sefz2YNtRr2Q"
      },
      "source": [
        "**Part 2 (35 points):** Update your network from part 1 with first an LSTM and then a GRU\n",
        "based cell structure (You can treat both as 2 separate implementations). Re-do the\n",
        "training and performance evaluation. What are the major differences you notice? Why\n",
        "do you think those differences exist between the 3 implementations (basic RNN, LSTM\n",
        "and GRU)?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:23:02.916672Z",
          "iopub.status.busy": "2024-02-27T17:23:02.915923Z",
          "iopub.status.idle": "2024-02-27T17:23:03.884401Z",
          "shell.execute_reply": "2024-02-27T17:23:03.883531Z",
          "shell.execute_reply.started": "2024-02-27T17:23:02.916643Z"
        },
        "id": "pmePYBT-Rr2Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# LSTM Implementation\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:23:03.885946Z",
          "iopub.status.busy": "2024-02-27T17:23:03.885615Z",
          "iopub.status.idle": "2024-02-27T17:23:03.897082Z",
          "shell.execute_reply": "2024-02-27T17:23:03.896273Z",
          "shell.execute_reply.started": "2024-02-27T17:23:03.885918Z"
        },
        "id": "sBSZ6gyjRr2Q",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:23:03.898871Z",
          "iopub.status.busy": "2024-02-27T17:23:03.89832Z",
          "iopub.status.idle": "2024-02-27T17:46:19.853957Z",
          "shell.execute_reply": "2024-02-27T17:46:19.853127Z",
          "shell.execute_reply.started": "2024-02-27T17:23:03.898844Z"
        },
        "id": "yeGNrPkDRr2Q",
        "outputId": "ebd0c27f-17b0-45a3-86ca-e8ed6117501d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1412/1412 [==============================] - 309s 216ms/step - loss: 0.3774 - accuracy: 0.8012 - val_loss: 0.2021 - val_accuracy: 0.9120\n",
            "Epoch 2/5\n",
            "1412/1412 [==============================] - 336s 238ms/step - loss: 0.1127 - accuracy: 0.9629 - val_loss: 0.1775 - val_accuracy: 0.9359\n",
            "Epoch 3/5\n",
            "1412/1412 [==============================] - 354s 250ms/step - loss: 0.0552 - accuracy: 0.9838 - val_loss: 0.2214 - val_accuracy: 0.9344\n",
            "Epoch 4/5\n",
            "1412/1412 [==============================] - 307s 217ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.3500 - val_accuracy: 0.9068\n",
            "Epoch 5/5\n",
            "1412/1412 [==============================] - 297s 211ms/step - loss: 0.0203 - accuracy: 0.9946 - val_loss: 0.3582 - val_accuracy: 0.9078\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:46:19.855556Z",
          "iopub.status.busy": "2024-02-27T17:46:19.855249Z",
          "iopub.status.idle": "2024-02-27T17:46:24.972147Z",
          "shell.execute_reply": "2024-02-27T17:46:24.971234Z",
          "shell.execute_reply.started": "2024-02-27T17:46:19.855528Z"
        },
        "id": "ml-Alb3dRr2Q",
        "outputId": "dedcc7ab-0f2f-4902-8d80-a243230830f9",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 8s 51ms/step - loss: 0.3654 - accuracy: 0.9099\n",
            "Loss: 0.36538437008857727\n",
            "Accuracy: 0.9099152684211731\n"
          ]
        }
      ],
      "source": [
        "# LSTM Implementation - Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:46:24.973816Z",
          "iopub.status.busy": "2024-02-27T17:46:24.973459Z",
          "iopub.status.idle": "2024-02-27T17:46:25.917521Z",
          "shell.execute_reply": "2024-02-27T17:46:25.91673Z",
          "shell.execute_reply.started": "2024-02-27T17:46:24.973784Z"
        },
        "id": "8ov1siLKRr2R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# GRU Implementation\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:46:25.922577Z",
          "iopub.status.busy": "2024-02-27T17:46:25.922283Z",
          "iopub.status.idle": "2024-02-27T17:46:25.933862Z",
          "shell.execute_reply": "2024-02-27T17:46:25.933073Z",
          "shell.execute_reply.started": "2024-02-27T17:46:25.922552Z"
        },
        "id": "J6seA7DcRr2R",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T17:46:25.935168Z",
          "iopub.status.busy": "2024-02-27T17:46:25.934895Z",
          "iopub.status.idle": "2024-02-27T18:09:08.274193Z",
          "shell.execute_reply": "2024-02-27T18:09:08.273309Z",
          "shell.execute_reply.started": "2024-02-27T17:46:25.935142Z"
        },
        "id": "5PhN-I20Rr2R",
        "outputId": "00240d08-410e-4b38-a1b6-3f44a936a381",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1412/1412 [==============================] - 270s 190ms/step - loss: 0.3951 - accuracy: 0.7653 - val_loss: 0.1483 - val_accuracy: 0.9453\n",
            "Epoch 2/5\n",
            "1412/1412 [==============================] - 269s 191ms/step - loss: 0.1066 - accuracy: 0.9637 - val_loss: 0.1417 - val_accuracy: 0.9536\n",
            "Epoch 3/5\n",
            "1412/1412 [==============================] - 274s 194ms/step - loss: 0.0505 - accuracy: 0.9851 - val_loss: 0.1899 - val_accuracy: 0.9490\n",
            "Epoch 4/5\n",
            "1412/1412 [==============================] - 271s 192ms/step - loss: 0.0285 - accuracy: 0.9921 - val_loss: 0.2584 - val_accuracy: 0.9297\n",
            "Epoch 5/5\n",
            "1412/1412 [==============================] - 273s 193ms/step - loss: 0.0179 - accuracy: 0.9953 - val_loss: 0.2179 - val_accuracy: 0.9385\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:09:08.275665Z",
          "iopub.status.busy": "2024-02-27T18:09:08.275371Z",
          "iopub.status.idle": "2024-02-27T18:09:11.891503Z",
          "shell.execute_reply": "2024-02-27T18:09:11.890533Z",
          "shell.execute_reply.started": "2024-02-27T18:09:08.275638Z"
        },
        "id": "vMZi-M6TRr2R",
        "outputId": "a5f30a80-32ab-407c-a5e6-5c44a5ba7f0e",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 6s 36ms/step - loss: 0.2005 - accuracy: 0.9438\n",
            "Loss: 0.2005155086517334\n",
            "Accuracy: 0.943796694278717\n"
          ]
        }
      ],
      "source": [
        "# GRU Implementation - Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mT5NxH6eRr2S"
      },
      "source": [
        "**Comparison of RNN Architectures:**\n",
        "\n",
        "* **LSTM:** Compared to the base RNN, the LSTM model exhibits increased loss (27%) and decreased accuracy. Additionally, the validation accuracy surpasses the training accuracy, which suggests overfitting.\n",
        "* **GRU:** Similar trends are observed with the GRU model, including a 19% loss and potential overfitting due to a higher validation accuracy.\n",
        "\n",
        "**Potential Contributing Factor:**\n",
        "\n",
        "* The significant variation in comment lengths (ranging from one word to lengthy comments) might have contributed to the different performance of these three architectures."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_o9ljCQ1Rr2S"
      },
      "source": [
        "**Part 3 (10 points):** Can you use the traditional feed-forward network to solve the same\n",
        "problem. Why or why not? (Hint: Can time series data be converted to usual features\n",
        "that can be used as input to a feed-forward network?)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQlJrB8WRr2S"
      },
      "source": [
        "For sentiment analysis tasks involving text, recurrent neural networks (RNNs) are generally preferred over traditional feed-forward networks due to the inherent sequential nature of language. Here's why:\n",
        "\n",
        "* **Temporal Dependence:** Sentences and phrases rely heavily on the order and context of words to convey meaning. Feed-forward networks, lacking memory, treat each word independently, potentially missing this crucial aspect.\n",
        "* **Memory Capability:** RNNs possess a memory mechanism that allows them to retain information from previous words in a sequence. This enables them to analyze the contextual relationships between words and capture how their order influences sentiment.\n",
        "* **Pattern Recognition:** This memory capability empowers RNNs to identify sequential patterns within text. For example, the phrase \"not a good movie\" conveys a different sentiment than \"a good movie, not.\" RNNs can use their memory to recognize such patterns and determine the overall sentiment more accurately.\n",
        "\n",
        "Therefore, considering the temporal dependence of language and the importance of contextual relationships in sentiment analysis, RNNs emerge as a more suitable choice compared to traditional feed-forward networks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOwL3eDpRr2S"
      },
      "source": [
        "# **Task 3 (25 points):**\n",
        "In this task, use any of the pre-trained word embeddings. The Wor2vec embedding link\n",
        "provided with the lecture notes can be useful to get started. Write your own code/function that\n",
        "uses these embeddings and outputs cosine similarity and a dissimilarity score for any 2 pair of\n",
        "words (read as user input). The dissimilarity score should be defined by you. You either can\n",
        "have your own idea of a dissimilarity score or refer to literature (cite the paper you used). In\n",
        "either case clearly describe how this score helps determine the dissimilarity between 2 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:40:46.96819Z",
          "iopub.status.busy": "2024-02-27T18:40:46.967815Z",
          "iopub.status.idle": "2024-02-27T18:40:52.090954Z",
          "shell.execute_reply": "2024-02-27T18:40:52.089786Z",
          "shell.execute_reply.started": "2024-02-27T18:40:46.96816Z"
        },
        "id": "X21MqeDERr2T",
        "trusted": true
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'tensorflow_hub'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-acedbd261580>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_hub\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodule_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://tfhub.dev/google/universal-sentence-encoder/4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow_hub'"
          ]
        }
      ],
      "source": [
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embeddings = hub.KerasLayer(module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:40:52.093468Z",
          "iopub.status.busy": "2024-02-27T18:40:52.093148Z",
          "iopub.status.idle": "2024-02-27T18:40:52.099891Z",
          "shell.execute_reply": "2024-02-27T18:40:52.098755Z",
          "shell.execute_reply.started": "2024-02-27T18:40:52.093438Z"
        },
        "id": "pDFwpfcrRr2T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def simFunction():\n",
        "  x = str(input('Please enter first word: '))\n",
        "  y = str(input('Please enter second word: '))\n",
        "  embed_x = embeddings([x])[0].numpy()\n",
        "  embed_y = embeddings([y])[0].numpy()\n",
        "  similarity = np.inner(embed_x, embed_y)/(np.linalg.norm(embed_x)*np.linalg.norm(embed_y)) # cosine similarity\n",
        "  dissimilarity = 1 - similarity\n",
        "  print(f'Cosine similarity of {x} and {y} is {similarity}.')\n",
        "  print(f'Dissimilarity of {x} and {y} is {dissimilarity}.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:55:38.690134Z",
          "iopub.status.busy": "2024-02-27T18:55:38.689726Z",
          "iopub.status.idle": "2024-02-27T18:56:02.829484Z",
          "shell.execute_reply": "2024-02-27T18:56:02.828501Z",
          "shell.execute_reply.started": "2024-02-27T18:55:38.69009Z"
        },
        "id": "b304jbevRr2T",
        "outputId": "cad7c73b-829d-4000-fd39-223daf1685fa",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter first word:  happy\n",
            "Please enter second word:  good\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity of happy and good is 0.612677812576294.\n",
            "Dissimilarity of happy and good is 0.38732218742370605.\n"
          ]
        }
      ],
      "source": [
        "simFunction()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T18:41:04.197991Z",
          "iopub.status.busy": "2024-02-27T18:41:04.197629Z",
          "iopub.status.idle": "2024-02-27T18:41:08.292428Z",
          "shell.execute_reply": "2024-02-27T18:41:08.29144Z",
          "shell.execute_reply.started": "2024-02-27T18:41:04.197964Z"
        },
        "id": "zxfAX_S-Rr2U",
        "outputId": "6a53ecaf-906c-489c-a9ac-5bee170a7943",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter first word:  love\n",
            "Please enter second word:  hate\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine similarity of love and hate is 0.5902369618415833.\n",
            "Dissimilarity of love and hate is 0.40976303815841675.\n"
          ]
        }
      ],
      "source": [
        "simFunction()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eTiKPmaSRr2U"
      },
      "source": [
        "In word embedding models, the dissimilarity between two words can be measured using the cosine distance metric. This is calculated as 1 minus the cosine similarity, which quantifies the directional difference between the word vectors in the embedding space."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "homework4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "python36",
      "language": "python",
      "name": "python36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
