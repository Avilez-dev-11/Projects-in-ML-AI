{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "homework4",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Avilez-dev-11/Projects-in-ML-AI/blob/main/homework4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 2 (75 points):**\n",
        "In this task, you will pick a dataset (time-series or any other form of\n",
        "sequential data) and an associated problem that can be solved via sequence models. You must\n",
        "describe why you need sequence models to solve this problem. Include a link to the dataset\n",
        "source. Next, you should pick an RNN framework that you would use to solve this problem (This\n",
        "framework can be in TensorFlow, PyTorch or any other Python Package)."
      ],
      "metadata": {
        "id": "Zq4oTpqgRr2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"/kaggle/input/chatgpt-sentiment-analysis/file.csv\")\n",
        "SEED = 5555"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:09.749125Z",
          "iopub.execute_input": "2024-02-27T17:06:09.749777Z",
          "iopub.status.idle": "2024-02-27T17:06:10.496169Z",
          "shell.execute_reply.started": "2024-02-27T17:06:09.749742Z",
          "shell.execute_reply": "2024-02-27T17:06:10.4953Z"
        },
        "trusted": true,
        "id": "Tjo-Zx9oRr2K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.497632Z",
          "iopub.execute_input": "2024-02-27T17:06:10.497929Z",
          "iopub.status.idle": "2024-02-27T17:06:10.508063Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.497903Z",
          "shell.execute_reply": "2024-02-27T17:06:10.507132Z"
        },
        "trusted": true,
        "id": "ReM8v3iGRr2L",
        "outputId": "ab0c4465-6d96-4a21-e357-e8b41d269c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Unnamed: 0                                             tweets   labels\n0           0  ChatGPT: Optimizing Language Models for Dialog...  neutral\n1           1  Try talking with ChatGPT, our new AI system wh...     good\n2           2  ChatGPT: Optimizing Language Models for Dialog...  neutral\n3           3  THRILLED to share that ChatGPT, our new model ...     good\n4           4  As of 2 minutes ago, @OpenAI released their ne...      bad",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n      <td>bad</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.509278Z",
          "iopub.execute_input": "2024-02-27T17:06:10.509591Z",
          "iopub.status.idle": "2024-02-27T17:06:10.584037Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.509565Z",
          "shell.execute_reply": "2024-02-27T17:06:10.582644Z"
        },
        "trusted": true,
        "id": "yjMt9l-GRr2L",
        "outputId": "90052d06-ba4d-4fc7-c7b3-ed5c0ddf7455"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Unnamed: 0    0\ntweets        0\nlabels        0\ndtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The absence of null values in the dataset ensures data integrity and reduces the need for data preprocessing steps like imputation. This can potentially improve the training efficiency and effectiveness of the model."
      ],
      "metadata": {
        "id": "L0jG8hAVRr2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(columns = [\"Unnamed: 0\"])\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.58693Z",
          "iopub.execute_input": "2024-02-27T17:06:10.587324Z",
          "iopub.status.idle": "2024-02-27T17:06:10.606817Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.587281Z",
          "shell.execute_reply": "2024-02-27T17:06:10.605792Z"
        },
        "trusted": true,
        "id": "qnhqz0oZRr2M",
        "outputId": "bc825500-4490-4747-b60f-c09a086bf557"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   tweets   labels\n0       ChatGPT: Optimizing Language Models for Dialog...  neutral\n1       Try talking with ChatGPT, our new AI system wh...     good\n2       ChatGPT: Optimizing Language Models for Dialog...  neutral\n3       THRILLED to share that ChatGPT, our new model ...     good\n4       As of 2 minutes ago, @OpenAI released their ne...      bad\n...                                                   ...      ...\n219289  Other Software Projects Are Now Trying to Repl...      bad\n219290  I asked #ChatGPT to write a #NYE Joke for SEOs...     good\n219291  chatgpt is being disassembled until it can onl...      bad\n219292  2023 predictions by #chatGPT. Nothing really s...      bad\n219293   From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0  neutral\n\n[219294 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ChatGPT: Optimizing Language Models for Dialog...</td>\n      <td>neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>219289</th>\n      <td>Other Software Projects Are Now Trying to Repl...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>219290</th>\n      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n      <td>good</td>\n    </tr>\n    <tr>\n      <th>219291</th>\n      <td>chatgpt is being disassembled until it can onl...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>219292</th>\n      <td>2023 predictions by #chatGPT. Nothing really s...</td>\n      <td>bad</td>\n    </tr>\n    <tr>\n      <th>219293</th>\n      <td>From ChatGPT, neat stuff https://t.co/qjjUF2Z2m0</td>\n      <td>neutral</td>\n    </tr>\n  </tbody>\n</table>\n<p>219294 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first column labeled \"unnamed: 0\" was removed from the dataset. This column did not contain meaningful information relevant to the sentiment analysis task and was therefore considered an artifact of the data import process. Removing it helps improve the clarity and efficiency of subsequent data processing and model training."
      ],
      "metadata": {
        "id": "rQo_NQ-RRr2M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df[\"labels\"]== \"bad\"]) # negative"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.60806Z",
          "iopub.execute_input": "2024-02-27T17:06:10.60843Z",
          "iopub.status.idle": "2024-02-27T17:06:10.667931Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.608399Z",
          "shell.execute_reply": "2024-02-27T17:06:10.667Z"
        },
        "trusted": true,
        "id": "0fUJxOyJRr2M",
        "outputId": "113be010-113b-47f7-ae6c-d1ba99d673c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "107796"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df[\"labels\"]== \"neutral\"]) # neutral"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.669291Z",
          "iopub.execute_input": "2024-02-27T17:06:10.669712Z",
          "iopub.status.idle": "2024-02-27T17:06:10.715766Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.669671Z",
          "shell.execute_reply": "2024-02-27T17:06:10.714857Z"
        },
        "trusted": true,
        "id": "GzUqhj39Rr2M",
        "outputId": "247b1848-c49a-4eff-eddf-aa29d8bbe031"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 31,
          "output_type": "execute_result",
          "data": {
            "text/plain": "55487"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df[df[\"labels\"]== \"good\"]) # positive"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.716943Z",
          "iopub.execute_input": "2024-02-27T17:06:10.717257Z",
          "iopub.status.idle": "2024-02-27T17:06:10.764463Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.717226Z",
          "shell.execute_reply": "2024-02-27T17:06:10.763463Z"
        },
        "trusted": true,
        "id": "vEUm4krwRr2M",
        "outputId": "55344564-ab8a-4419-8dce-4185781b578c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "56011"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of the data revealed a class imbalance, with significantly more negative comments (107796) than positive comments (56011). To address this and ensure a more balanced representation during model training, a downsampling technique was used. This involved randomly removing a specific number of observations from the majority class (negative comments) to match the size of the minority class (positive comments)."
      ],
      "metadata": {
        "id": "61m0dBpKRr2N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n",
        "\n",
        "# Load the dataset (assuming you have it in a DataFrame called 'df')\n",
        "\n",
        "# Identify indices of negative comments\n",
        "negative_indices = df[df['labels'] == 'bad'].index\n",
        "neutral_indices = len(df[df['labels'] == 'neutral'])\n",
        "\n",
        "# Calculate the number of negative comments to remove based on desired ratio or fixed number\n",
        "num_negative_to_remove = len(negative_indices) - neutral_indices  # For 1:1 ratio\n",
        "\n",
        "# Create a DataFrame of just those indices\n",
        "negatives_to_remove = negative_indices.to_frame(name='index')\n",
        "\n",
        "# Undersample the positives to remove (if any)\n",
        "if num_negative_to_remove > 0:\n",
        "    df_downsampled = resample(negatives_to_remove,\n",
        "                              replace=False,  # Don't sample with replacement\n",
        "                              n_samples=num_negative_to_remove,\n",
        "                              random_state=42)  # For reproducibility\n",
        "\n",
        "    # Drop those indices from the original DataFrame\n",
        "    df = df.drop(df_downsampled['index'])\n",
        "\n",
        "# Check the new distribution\n",
        "print(\"Sentiment distribution after undersampling:\")\n",
        "print(df['labels'].value_counts())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.765795Z",
          "iopub.execute_input": "2024-02-27T17:06:10.766227Z",
          "iopub.status.idle": "2024-02-27T17:06:10.912391Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.766191Z",
          "shell.execute_reply": "2024-02-27T17:06:10.91143Z"
        },
        "trusted": true,
        "id": "RagJ5mjERr2N",
        "outputId": "ce893558-c0a4-47c7-be76-69bf687f5e8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Sentiment distribution after undersampling:\nlabels\ngood       56011\nneutral    55487\nbad        55487\nName: count, dtype: int64\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df[\"labels\"] != \"neutral\"]# remove neutral\n",
        "len(df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.913658Z",
          "iopub.execute_input": "2024-02-27T17:06:10.914017Z",
          "iopub.status.idle": "2024-02-27T17:06:10.956704Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.913984Z",
          "shell.execute_reply": "2024-02-27T17:06:10.955898Z"
        },
        "trusted": true,
        "id": "TdE74L3URr2N",
        "outputId": "e6dd5fed-c817-47fd-c262-8a550bcb0d13"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "111498"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"labels\"] = df[\"labels\"].replace(\"bad\", 0)\n",
        "df[\"labels\"] = df[\"labels\"].replace(\"good\", 1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:10.99648Z",
          "iopub.execute_input": "2024-02-27T17:06:10.996899Z",
          "iopub.status.idle": "2024-02-27T17:06:11.092326Z",
          "shell.execute_reply.started": "2024-02-27T17:06:10.996865Z",
          "shell.execute_reply": "2024-02-27T17:06:11.091378Z"
        },
        "trusted": true,
        "id": "03wFKQFSRr2N",
        "outputId": "63e6cbc9-7fc7-401e-c196-e3c9bc78cf4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/623871756.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  df[\"labels\"] = df[\"labels\"].replace(\"good\", 1)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This dataset initially included ChatGPT tweets categorized under the sentiments: bad, neutral, and good. To focus on identifying distinctly negative or positive sentiments, neutral observations were removed. This decision was made because neutral tweets might not contribute strongly to model training when the goal is to distinguish between clear emotional states. Despite this filtering, we retain a substantial dataset that provides ample data for robust model training."
      ],
      "metadata": {
        "id": "qkI4Dy05Rr2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 1 (30 points):** Implement your RNN either using an existing framework OR you can\n",
        "implement your own RNN cell structure. In either case, describe the structure of your\n",
        "RNN and the activation functions you are using for each time step and in the output\n",
        "layer. Define a metric you will use to measure the performance of your model (NOTE:\n",
        "Performance should be measured both for the validation set and the test set)."
      ],
      "metadata": {
        "id": "vJOQwsVmRr2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:11.09358Z",
          "iopub.execute_input": "2024-02-27T17:06:11.093886Z",
          "iopub.status.idle": "2024-02-27T17:06:11.105467Z",
          "shell.execute_reply.started": "2024-02-27T17:06:11.093859Z",
          "shell.execute_reply": "2024-02-27T17:06:11.104327Z"
        },
        "trusted": true,
        "id": "HK6tq5uYRr2O",
        "outputId": "5c79f228-4a25-4fce-c347-02acb95c6cf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   tweets  labels\n1       Try talking with ChatGPT, our new AI system wh...       1\n3       THRILLED to share that ChatGPT, our new model ...       1\n4       As of 2 minutes ago, @OpenAI released their ne...       0\n5       Just launched ChatGPT, our new AI system which...       1\n7       ChatGPT coming out strong refusing to help me ...       1\n...                                                   ...     ...\n219285  Podcast returns in 2023! 🐈🌙\\n.\\n#ai #chatgpt #...       0\n219286  There's now an open source alternative to Chat...       1\n219287  One of my new favorite thing to do with #ChatG...       1\n219290  I asked #ChatGPT to write a #NYE Joke for SEOs...       1\n219291  chatgpt is being disassembled until it can onl...       0\n\n[111498 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As of 2 minutes ago, @OpenAI released their ne...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Just launched ChatGPT, our new AI system which...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ChatGPT coming out strong refusing to help me ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>219285</th>\n      <td>Podcast returns in 2023! 🐈🌙\\n.\\n#ai #chatgpt #...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>219286</th>\n      <td>There's now an open source alternative to Chat...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219287</th>\n      <td>One of my new favorite thing to do with #ChatG...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219290</th>\n      <td>I asked #ChatGPT to write a #NYE Joke for SEOs...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219291</th>\n      <td>chatgpt is being disassembled until it can onl...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>111498 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def clean_comment(comment: str) -> str:\n",
        "    \"\"\"\n",
        "    Cleans text, removing special characters, hashtags, and mentions while\n",
        "    preserving spaces and essential punctuation.\n",
        "\n",
        "    Args:\n",
        "        comment: The text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "        The cleaned text.\n",
        "    \"\"\"\n",
        "\n",
        "    # Regular expression to match and remove special characters\n",
        "    pattern = r\"[^a-zA-Z0-9\\s\\.!?,\\(\\)]+\"\n",
        "\n",
        "    # Clean the text using regular expressions\n",
        "    cleaned_text = re.sub(pattern, \"\", comment)\n",
        "\n",
        "    # Remove leading and trailing whitespace\n",
        "    cleaned_text = cleaned_text.strip()\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "# Apply the cleaning function to the \"Comment\" column\n",
        "df[\"tweets\"] = df[\"tweets\"].apply(clean_comment)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:11.106789Z",
          "iopub.execute_input": "2024-02-27T17:06:11.107085Z",
          "iopub.status.idle": "2024-02-27T17:06:12.191847Z",
          "shell.execute_reply.started": "2024-02-27T17:06:11.10706Z",
          "shell.execute_reply": "2024-02-27T17:06:12.190928Z"
        },
        "trusted": true,
        "id": "qP9IF6T0Rr2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:57:12.285972Z",
          "iopub.execute_input": "2024-02-27T18:57:12.286372Z",
          "iopub.status.idle": "2024-02-27T18:57:12.298312Z",
          "shell.execute_reply.started": "2024-02-27T18:57:12.28634Z",
          "shell.execute_reply": "2024-02-27T18:57:12.297392Z"
        },
        "trusted": true,
        "id": "meWSFmaHRr2O",
        "outputId": "4a166b6e-55ed-4e01-e93c-807fd083ca9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 87,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   tweets  labels\n1       Try talking with ChatGPT, our new AI system wh...       1\n3       THRILLED to share that ChatGPT, our new model ...       1\n4       As of 2 minutes ago, OpenAI released their new...       0\n5       Just launched ChatGPT, our new AI system which...       1\n7       ChatGPT coming out strong refusing to help me ...       1\n...                                                   ...     ...\n219285  Podcast returns in 2023! n.nai chatgpt artific...       0\n219286  Theres now an open source alternative to ChatG...       1\n219287  One of my new favorite thing to do with ChatGP...       1\n219290  I asked ChatGPT to write a NYE Joke for SEOs a...       1\n219291  chatgpt is being disassembled until it can onl...       0\n\n[111498 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweets</th>\n      <th>labels</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>Try talking with ChatGPT, our new AI system wh...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>THRILLED to share that ChatGPT, our new model ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>As of 2 minutes ago, OpenAI released their new...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Just launched ChatGPT, our new AI system which...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>ChatGPT coming out strong refusing to help me ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>219285</th>\n      <td>Podcast returns in 2023! n.nai chatgpt artific...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>219286</th>\n      <td>Theres now an open source alternative to ChatG...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219287</th>\n      <td>One of my new favorite thing to do with ChatGP...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219290</th>\n      <td>I asked ChatGPT to write a NYE Joke for SEOs a...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>219291</th>\n      <td>chatgpt is being disassembled until it can onl...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>111498 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:12.193023Z",
          "iopub.execute_input": "2024-02-27T17:06:12.193324Z",
          "iopub.status.idle": "2024-02-27T17:06:12.197931Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.193299Z",
          "shell.execute_reply": "2024-02-27T17:06:12.196804Z"
        },
        "trusted": true,
        "id": "jcYVMBusRr2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_to_tfds(dataframe):\n",
        "\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((dataframe['tweets'], dataframe['labels']))\n",
        "  dataset = dataset.shuffle(buffer_size=len(dataframe), seed=0)\n",
        "  return dataset.batch(64).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "training_set = df.copy()\n",
        "\n",
        "train, dev = train_test_split(training_set, test_size=0.1, random_state = 0)\n",
        "train, test = train_test_split(train, test_size = 0.1, random_state = 0)\n",
        "\n",
        "train_ds = convert_to_tfds(train)\n",
        "valid_ds = convert_to_tfds(dev)\n",
        "test_ds = convert_to_tfds(test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:12.199059Z",
          "iopub.execute_input": "2024-02-27T17:06:12.199366Z",
          "iopub.status.idle": "2024-02-27T17:06:12.295146Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.199342Z",
          "shell.execute_reply": "2024-02-27T17:06:12.294335Z"
        },
        "trusted": true,
        "id": "fXkhf-R1Rr2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = tf.keras.layers.TextVectorization()\n",
        "encoder.adapt(train_ds.map(lambda text, label: text))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:12.296478Z",
          "iopub.execute_input": "2024-02-27T17:06:12.296795Z",
          "iopub.status.idle": "2024-02-27T17:06:15.794176Z",
          "shell.execute_reply.started": "2024-02-27T17:06:12.296768Z",
          "shell.execute_reply": "2024-02-27T17:06:15.79331Z"
        },
        "trusted": true,
        "id": "wsEZb9fZRr2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(encoder.get_vocabulary())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:15.795443Z",
          "iopub.execute_input": "2024-02-27T17:06:15.795822Z",
          "iopub.status.idle": "2024-02-27T17:06:16.498609Z",
          "shell.execute_reply.started": "2024-02-27T17:06:15.795795Z",
          "shell.execute_reply": "2024-02-27T17:06:16.497644Z"
        },
        "trusted": true,
        "id": "_tVp4Q3ORr2P",
        "outputId": "09129951-78fd-4a9c-98b0-e7f9a4cd55e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 43,
          "output_type": "execute_result",
          "data": {
            "text/plain": "160530"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.SimpleRNN(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:16.499814Z",
          "iopub.execute_input": "2024-02-27T17:06:16.500125Z",
          "iopub.status.idle": "2024-02-27T17:06:17.43402Z",
          "shell.execute_reply.started": "2024-02-27T17:06:16.50008Z",
          "shell.execute_reply": "2024-02-27T17:06:17.433156Z"
        },
        "trusted": true,
        "id": "1dWfZQt9Rr2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:17.43539Z",
          "iopub.execute_input": "2024-02-27T17:06:17.43578Z",
          "iopub.status.idle": "2024-02-27T17:06:17.450482Z",
          "shell.execute_reply.started": "2024-02-27T17:06:17.435739Z",
          "shell.execute_reply": "2024-02-27T17:06:17.4495Z"
        },
        "trusted": true,
        "id": "iOeKU2QMRr2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:06:17.451655Z",
          "iopub.execute_input": "2024-02-27T17:06:17.451985Z",
          "iopub.status.idle": "2024-02-27T17:23:00.581789Z",
          "shell.execute_reply.started": "2024-02-27T17:06:17.451958Z",
          "shell.execute_reply": "2024-02-27T17:23:00.580776Z"
        },
        "trusted": true,
        "id": "CeV15O12Rr2P",
        "outputId": "263f5334-a2e7-4be0-db7d-5669f62b0ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n1412/1412 [==============================] - 233s 163ms/step - loss: 0.3961 - accuracy: 0.7821 - val_loss: 0.1499 - val_accuracy: 0.9484\nEpoch 2/5\n1412/1412 [==============================] - 194s 137ms/step - loss: 0.1119 - accuracy: 0.9618 - val_loss: 0.1407 - val_accuracy: 0.9469\nEpoch 3/5\n1412/1412 [==============================] - 192s 136ms/step - loss: 0.0540 - accuracy: 0.9842 - val_loss: 0.1268 - val_accuracy: 0.9599\nEpoch 4/5\n1412/1412 [==============================] - 194s 137ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.1502 - val_accuracy: 0.9547\nEpoch 5/5\n1412/1412 [==============================] - 190s 135ms/step - loss: 0.0179 - accuracy: 0.9950 - val_loss: 0.1775 - val_accuracy: 0.9479\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:23:00.58319Z",
          "iopub.execute_input": "2024-02-27T17:23:00.583823Z",
          "iopub.status.idle": "2024-02-27T17:23:02.913742Z",
          "shell.execute_reply.started": "2024-02-27T17:23:00.583787Z",
          "shell.execute_reply": "2024-02-27T17:23:02.912742Z"
        },
        "trusted": true,
        "id": "OJeIG1E-Rr2P",
        "outputId": "22414a21-6176-4693-9d29-c8722750b5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "157/157 [==============================] - 2s 15ms/step - loss: 0.1868 - accuracy: 0.9422\nLoss: 0.18675735592842102\nAccuracy: 0.9422022700309753\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model utilizes a bidirectional recurrent neural network (BRNN) with an embedding layer for processing tokenized input data. Training the model required significant computation time, but the training accuracy increased steadily with additional epochs. While the final training accuracy reached a high of 94% with a relatively low loss of 18%, a potential case of underfitting is suggested by the discrepancy between the training (94%) and validation/test accuracies."
      ],
      "metadata": {
        "id": "gbq9jpP3Rr2P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 2 (35 points):** Update your network from part 1 with first an LSTM and then a GRU\n",
        "based cell structure (You can treat both as 2 separate implementations). Re-do the\n",
        "training and performance evaluation. What are the major differences you notice? Why\n",
        "do you think those differences exist between the 3 implementations (basic RNN, LSTM\n",
        "and GRU)?"
      ],
      "metadata": {
        "id": "Sefz2YNtRr2Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Implementation\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:23:02.915923Z",
          "iopub.execute_input": "2024-02-27T17:23:02.916672Z",
          "iopub.status.idle": "2024-02-27T17:23:03.884401Z",
          "shell.execute_reply.started": "2024-02-27T17:23:02.916643Z",
          "shell.execute_reply": "2024-02-27T17:23:03.883531Z"
        },
        "trusted": true,
        "id": "pmePYBT-Rr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:23:03.885615Z",
          "iopub.execute_input": "2024-02-27T17:23:03.885946Z",
          "iopub.status.idle": "2024-02-27T17:23:03.897082Z",
          "shell.execute_reply.started": "2024-02-27T17:23:03.885918Z",
          "shell.execute_reply": "2024-02-27T17:23:03.896273Z"
        },
        "trusted": true,
        "id": "sBSZ6gyjRr2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:23:03.89832Z",
          "iopub.execute_input": "2024-02-27T17:23:03.898871Z",
          "iopub.status.idle": "2024-02-27T17:46:19.853957Z",
          "shell.execute_reply.started": "2024-02-27T17:23:03.898844Z",
          "shell.execute_reply": "2024-02-27T17:46:19.853127Z"
        },
        "trusted": true,
        "id": "yeGNrPkDRr2Q",
        "outputId": "ebd0c27f-17b0-45a3-86ca-e8ed6117501d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n1412/1412 [==============================] - 291s 203ms/step - loss: 0.3771 - accuracy: 0.8089 - val_loss: 0.1707 - val_accuracy: 0.9453\nEpoch 2/5\n1412/1412 [==============================] - 266s 188ms/step - loss: 0.1224 - accuracy: 0.9608 - val_loss: 0.1392 - val_accuracy: 0.9531\nEpoch 3/5\n1412/1412 [==============================] - 268s 190ms/step - loss: 0.0586 - accuracy: 0.9824 - val_loss: 0.1554 - val_accuracy: 0.9536\nEpoch 4/5\n1412/1412 [==============================] - 269s 191ms/step - loss: 0.0327 - accuracy: 0.9910 - val_loss: 0.1795 - val_accuracy: 0.9510\nEpoch 5/5\n1412/1412 [==============================] - 267s 189ms/step - loss: 0.0204 - accuracy: 0.9946 - val_loss: 0.1536 - val_accuracy: 0.9568\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Implementation - Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:46:19.855249Z",
          "iopub.execute_input": "2024-02-27T17:46:19.855556Z",
          "iopub.status.idle": "2024-02-27T17:46:24.972147Z",
          "shell.execute_reply.started": "2024-02-27T17:46:19.855528Z",
          "shell.execute_reply": "2024-02-27T17:46:24.971234Z"
        },
        "trusted": true,
        "id": "ml-Alb3dRr2Q",
        "outputId": "dedcc7ab-0f2f-4902-8d80-a243230830f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "157/157 [==============================] - 4s 22ms/step - loss: 0.1632 - accuracy: 0.9533\nLoss: 0.16315485537052155\nAccuracy: 0.9532635807991028\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU Implementation\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "        encoder,\n",
        "        tf.keras.layers.Embedding(\n",
        "            input_dim = len(encoder.get_vocabulary()),\n",
        "            output_dim = 64,\n",
        "            mask_zero = True\n",
        "        ),\n",
        "        tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64, activation='relu')),\n",
        "        tf.keras.layers.Dense(64, activation='relu'),\n",
        "        tf.keras.layers.Dense(1)\n",
        "])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:46:24.973459Z",
          "iopub.execute_input": "2024-02-27T17:46:24.973816Z",
          "iopub.status.idle": "2024-02-27T17:46:25.917521Z",
          "shell.execute_reply.started": "2024-02-27T17:46:24.973784Z",
          "shell.execute_reply": "2024-02-27T17:46:25.91673Z"
        },
        "trusted": true,
        "id": "8ov1siLKRr2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:46:25.922283Z",
          "iopub.execute_input": "2024-02-27T17:46:25.922577Z",
          "iopub.status.idle": "2024-02-27T17:46:25.933862Z",
          "shell.execute_reply.started": "2024-02-27T17:46:25.922552Z",
          "shell.execute_reply": "2024-02-27T17:46:25.933073Z"
        },
        "trusted": true,
        "id": "J6seA7DcRr2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=5,\n",
        "                    validation_data=valid_ds,\n",
        "                    validation_steps=30)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T17:46:25.934895Z",
          "iopub.execute_input": "2024-02-27T17:46:25.935168Z",
          "iopub.status.idle": "2024-02-27T18:09:08.274193Z",
          "shell.execute_reply.started": "2024-02-27T17:46:25.935142Z",
          "shell.execute_reply": "2024-02-27T18:09:08.273309Z"
        },
        "trusted": true,
        "id": "5PhN-I20Rr2R",
        "outputId": "00240d08-410e-4b38-a1b6-3f44a936a381"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1/5\n1412/1412 [==============================] - 298s 208ms/step - loss: 0.3923 - accuracy: 0.7672 - val_loss: 0.1783 - val_accuracy: 0.9182\nEpoch 2/5\n1412/1412 [==============================] - 268s 189ms/step - loss: 0.1047 - accuracy: 0.9645 - val_loss: 0.1644 - val_accuracy: 0.9365\nEpoch 3/5\n1412/1412 [==============================] - 264s 187ms/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.1566 - val_accuracy: 0.9542\nEpoch 4/5\n1412/1412 [==============================] - 266s 188ms/step - loss: 0.0286 - accuracy: 0.9920 - val_loss: 0.1715 - val_accuracy: 0.9474\nEpoch 5/5\n1412/1412 [==============================] - 267s 189ms/step - loss: 0.0181 - accuracy: 0.9951 - val_loss: 0.2988 - val_accuracy: 0.9292\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GRU Implementation - Get Loss and Accuracy of test set\n",
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print('Loss:', loss)\n",
        "print('Accuracy:', accuracy)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:09:08.275371Z",
          "iopub.execute_input": "2024-02-27T18:09:08.275665Z",
          "iopub.status.idle": "2024-02-27T18:09:11.891503Z",
          "shell.execute_reply.started": "2024-02-27T18:09:08.275638Z",
          "shell.execute_reply": "2024-02-27T18:09:11.890533Z"
        },
        "trusted": true,
        "id": "vMZi-M6TRr2R",
        "outputId": "a5f30a80-32ab-407c-a5e6-5c44a5ba7f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "157/157 [==============================] - 4s 23ms/step - loss: 0.2687 - accuracy: 0.9252\nLoss: 0.26874470710754395\nAccuracy: 0.9251619577407837\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison of RNN Architectures:**\n",
        "\n",
        "* **LSTM:** Compared to the base RNN, the LSTM model exhibits increased loss (27%) and decreased accuracy. Additionally, the validation accuracy surpasses the training accuracy, which suggests overfitting.\n",
        "* **GRU:** Similar trends are observed with the GRU model, including a 19% loss and potential overfitting due to a higher validation accuracy.\n",
        "\n",
        "**Potential Contributing Factor:**\n",
        "\n",
        "* The significant variation in comment lengths (ranging from one word to lengthy comments) might have contributed to the different performance of these three architectures."
      ],
      "metadata": {
        "id": "mT5NxH6eRr2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Part 3 (10 points):** Can you use the traditional feed-forward network to solve the same\n",
        "problem. Why or why not? (Hint: Can time series data be converted to usual features\n",
        "that can be used as input to a feed-forward network?)"
      ],
      "metadata": {
        "id": "_o9ljCQ1Rr2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For sentiment analysis tasks involving text, recurrent neural networks (RNNs) are generally preferred over traditional feed-forward networks due to the inherent sequential nature of language. Here's why:\n",
        "\n",
        "* **Temporal Dependence:** Sentences and phrases rely heavily on the order and context of words to convey meaning. Feed-forward networks, lacking memory, treat each word independently, potentially missing this crucial aspect.\n",
        "* **Memory Capability:** RNNs possess a memory mechanism that allows them to retain information from previous words in a sequence. This enables them to analyze the contextual relationships between words and capture how their order influences sentiment.\n",
        "* **Pattern Recognition:** This memory capability empowers RNNs to identify sequential patterns within text. For example, the phrase \"not a good movie\" conveys a different sentiment than \"a good movie, not.\" RNNs can use their memory to recognize such patterns and determine the overall sentiment more accurately.\n",
        "\n",
        "Therefore, considering the temporal dependence of language and the importance of contextual relationships in sentiment analysis, RNNs emerge as a more suitable choice compared to traditional feed-forward networks."
      ],
      "metadata": {
        "id": "xQlJrB8WRr2S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Task 3 (25 points):**\n",
        "In this task, use any of the pre-trained word embeddings. The Wor2vec embedding link\n",
        "provided with the lecture notes can be useful to get started. Write your own code/function that\n",
        "uses these embeddings and outputs cosine similarity and a dissimilarity score for any 2 pair of\n",
        "words (read as user input). The dissimilarity score should be defined by you. You either can\n",
        "have your own idea of a dissimilarity score or refer to literature (cite the paper you used). In\n",
        "either case clearly describe how this score helps determine the dissimilarity between 2 words."
      ],
      "metadata": {
        "id": "yOwL3eDpRr2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
        "embeddings = hub.KerasLayer(module_url)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:40:46.967815Z",
          "iopub.execute_input": "2024-02-27T18:40:46.96819Z",
          "iopub.status.idle": "2024-02-27T18:40:52.090954Z",
          "shell.execute_reply.started": "2024-02-27T18:40:46.96816Z",
          "shell.execute_reply": "2024-02-27T18:40:52.089786Z"
        },
        "trusted": true,
        "id": "X21MqeDERr2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simFunction():\n",
        "  x = str(input('Please enter first word: '))\n",
        "  y = str(input('Please enter second word: '))\n",
        "  embed_x = embeddings([x])[0].numpy()\n",
        "  embed_y = embeddings([y])[0].numpy()\n",
        "  similarity = np.inner(embed_x, embed_y)/(np.linalg.norm(embed_x)*np.linalg.norm(embed_y)) # cosine similarity\n",
        "  dissimilarity = 1 - similarity\n",
        "  print(f'Cosine similarity of {x} and {y} is {similarity}.')\n",
        "  print(f'Dissimilarity of {x} and {y} is {dissimilarity}.')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:40:52.093148Z",
          "iopub.execute_input": "2024-02-27T18:40:52.093468Z",
          "iopub.status.idle": "2024-02-27T18:40:52.099891Z",
          "shell.execute_reply.started": "2024-02-27T18:40:52.093438Z",
          "shell.execute_reply": "2024-02-27T18:40:52.098755Z"
        },
        "trusted": true,
        "id": "pDFwpfcrRr2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simFunction()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:55:38.689726Z",
          "iopub.execute_input": "2024-02-27T18:55:38.690134Z",
          "iopub.status.idle": "2024-02-27T18:56:02.829484Z",
          "shell.execute_reply.started": "2024-02-27T18:55:38.69009Z",
          "shell.execute_reply": "2024-02-27T18:56:02.828501Z"
        },
        "trusted": true,
        "id": "b304jbevRr2T",
        "outputId": "cad7c73b-829d-4000-fd39-223daf1685fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Please enter first word:  happy\nPlease enter second word:  good\n"
        },
        {
          "name": "stdout",
          "text": "Cosine similarity of happy and good is 0.612677812576294.\nDissimilarity of happy and good is 0.38732218742370605.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simFunction()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-02-27T18:41:04.197629Z",
          "iopub.execute_input": "2024-02-27T18:41:04.197991Z",
          "iopub.status.idle": "2024-02-27T18:41:08.292428Z",
          "shell.execute_reply.started": "2024-02-27T18:41:04.197964Z",
          "shell.execute_reply": "2024-02-27T18:41:08.29144Z"
        },
        "trusted": true,
        "id": "zxfAX_S-Rr2U",
        "outputId": "6a53ecaf-906c-489c-a9ac-5bee170a7943"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "Please enter first word:  love\nPlease enter second word:  hate\n"
        },
        {
          "name": "stdout",
          "text": "Cosine similarity of love and hate is 0.5902369618415833.\nDissimilarity of love and hate is 0.40976303815841675.\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In word embedding models, the dissimilarity between two words can be measured using the cosine distance metric. This is calculated as 1 minus the cosine similarity, which quantifies the directional difference between the word vectors in the embedding space."
      ],
      "metadata": {
        "id": "eTiKPmaSRr2U"
      }
    }
  ]
}